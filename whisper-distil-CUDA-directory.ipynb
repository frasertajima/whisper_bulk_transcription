{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Modification of whisper-distil.ipynb to handle bulk transcriptions of an entire directory. Added a file renaming function to remove spaces from any audio filename (as ffmpeg will cut off after the space).\n",
    "\n",
    "CAUTION: MAKE SURE TO BACKUP AUDIO FILES IF THEY HAVE SPACES IN THEIR NAMES AS THEY WILL BE RENAMED (AND THE METADATA ALTERED). For file names without spaces, the original file is not renamed and a copy is made in a compatible audio format."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'2.2.1+cu121'"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "torch.__version__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# need cuda for vastly faster transcription\n",
    "#47 seconds for a full 30 min podcast! Insanely fast\n",
    "torch.cuda.is_available()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-03-17 11:06:30.751802: I tensorflow/core/util/port.cc:113] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2024-03-17 11:06:30.791172: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 AVX_VNNI FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2024-03-17 11:06:31.481781: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n",
      "2024-03-17 11:06:31.761755: I itex/core/wrapper/itex_cpu_wrapper.cc:52] Intel Extension for Tensorflow* AVX2 CPU backend is loaded.\n",
      "2024-03-17 11:06:31.763611: W itex/core/wrapper/itex_gpu_wrapper.cc:32] Could not load dynamic library: libimf.so: cannot open shared object file: No such file or directory\n",
      "2024-03-17 11:06:31.796920: W itex/core/ops/op_init.cc:58] Op: _QuantizedMaxPool3D is already registered in Tensorflow\n",
      "2024-03-17 11:06:31.806746: E itex/core/wrapper/itex_gpu_wrapper.cc:49] Could not load Intel Extension for Tensorflow* GPU backend, GPU will not be used.\n",
      "If you need help, create an issue at https://github.com/intel/intel-extension-for-tensorflow/issues\n",
      "2024-03-17 11:06:31.806983: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:998] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2024-03-17 11:06:31.807430: W tensorflow/core/common_runtime/gpu/gpu_device.cc:2251] Cannot dlopen some GPU libraries. Please make sure the missing libraries mentioned above are installed properly if you would like to use GPU. Follow the guide at https://www.tensorflow.org/install/gpu for how to download and setup the required libraries for your platform.\n",
      "Skipping registering GPU devices...\n",
      "2024-03-17 11:06:31.807468: E itex/core/wrapper/itex_gpu_wrapper.cc:49] Could not load Intel Extension for Tensorflow* GPU backend, GPU will not be used.\n",
      "If you need help, create an issue at https://github.com/intel/intel-extension-for-tensorflow/issues\n",
      "You are attempting to use Flash Attention 2.0 with a model not initialized on GPU. Make sure to move the model to GPU after initializing it on CPU with `model.to('cuda')`.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda:0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n"
     ]
    }
   ],
   "source": [
    "# https://github.com/huggingface/distil-whisper\n",
    "# conda activate py310\n",
    "import torch\n",
    "import subprocess\n",
    "import os\n",
    "import glob\n",
    "import shutil\n",
    "from transformers import AutoModelForSpeechSeq2Seq, AutoProcessor, pipeline\n",
    "\n",
    "device = \"cuda:0\" if torch.cuda.is_available() else \"cpu\"\n",
    "torch_dtype = torch.float16 if torch.cuda.is_available() else torch.float32\n",
    "print(device)\n",
    "\n",
    "# biggest model for highest quality\n",
    "model_id = \"distil-whisper/distil-large-v2\"\n",
    "model = AutoModelForSpeechSeq2Seq.from_pretrained(\n",
    "    model_id, \n",
    "    torch_dtype=torch_dtype, \n",
    "    low_cpu_mem_usage=True, \n",
    "    use_safetensors=True,\n",
    "    attn_implementation=\"flash_attention_2\")        # updated\n",
    "model.to(device)\n",
    "processor = AutoProcessor.from_pretrained(model_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# set podcasts=True to copy all downloaded podcasts to the whisper.cpp/samples directory\n",
    "# example file location is from great Gnome Podcast app:  https://apps.gnome.org/en-GB/Podcasts/ \n",
    "podcasts = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# rename all audio files with spaces in their name\n",
    "# poe.com assisted code\n",
    "# Specify the directory where the files are located\n",
    "directory = '/var/home/fraser/machine_learning/whisper.cpp/samples/'\n",
    "#directory = '/var/home/fraser/Music/Voice_Memos/'\n",
    "\n",
    "if podcasts:\n",
    "    # copy podcast from subdirectories with spaces to whisper sample directory\n",
    "    source_directory = '/var/home/fraser/.var/app/org.gnome.Podcasts/data/gnome-podcasts/Downloads/'\n",
    "    # Traverse the source directory and its subdirectories\n",
    "    for root, directories, files in os.walk(source_directory):\n",
    "        for file in files:\n",
    "            source_path = os.path.join(root, file)\n",
    "            destination_path = os.path.join(directory, file)\n",
    "            # Copy the file to the destination directory\n",
    "            shutil.copy2(source_path, destination_path)\n",
    "\n",
    "# Get a list of all audio files, .m4a, .mp3, and .wav files, in the directory\n",
    "# added *.m2a for podcasts\n",
    "files = glob.glob(os.path.join(directory, '*.m4a')) + \\\n",
    "        glob.glob(os.path.join(directory, '*.mp3')) + \\\n",
    "        glob.glob(os.path.join(directory, '*.m2a')) + \\\n",
    "        glob.glob(os.path.join(directory, '*.ogg')) + \\\n",
    "        glob.glob(os.path.join(directory, '*.wav'))\n",
    "\n",
    "# Iterate over the files (use this approach also for directory transcription)\n",
    "# CAUTION: this overwrites files with spaces in their names such as 'Track 11.wav' to 'Track-11.wav' \n",
    "# by overwriting the file, it permits processing but alters the metadata to date file saved=today\n",
    "for file in files:\n",
    "    # If the file name contains a space\n",
    "    if ' ' in file:\n",
    "        # Replace the spaces with hyphens\n",
    "        new_name = file.replace(' ', '-')\n",
    "        # Rename the file\n",
    "        os.rename(file, new_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/var/home/fraser/machine_learning/whisper.cpp/samples/1.m2a\n",
      "/var/home/fraser/machine_learning/whisper.cpp/samples/1.m2a-output.wav\n",
      "Audio coverted successfully.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ffmpeg version 4.4 Copyright (c) 2000-2021 the FFmpeg developers\n",
      "  built with gcc 9.3.0 (crosstool-NG 1.24.0.133_b0863d8_dirty)\n",
      "  configuration: --prefix=/root/miniconda3/envs/conda_bld/conda-bld/ffmpeg_1635335682798/_h_env_placehold_placehold_placehold_placehold_placehold_placehold_placehold_placehold_placehold_placehold_placehold_placehold_placehold_placehold_placehold_placehold_placehold_placehold_place --cc=/root/miniconda3/envs/conda_bld/conda-bld/ffmpeg_1635335682798/_build_env/bin/x86_64-conda-linux-gnu-cc --disable-doc --disable-openssl --enable-avresample --enable-hardcoded-tables --enable-libfreetype --enable-libopenh264 --enable-pic --enable-pthreads --enable-shared --disable-static --enable-version3 --enable-zlib --enable-libmp3lame\n",
      "  libavutil      56. 70.100 / 56. 70.100\n",
      "  libavcodec     58.134.100 / 58.134.100\n",
      "  libavformat    58. 76.100 / 58. 76.100\n",
      "  libavdevice    58. 13.100 / 58. 13.100\n",
      "  libavfilter     7.110.100 /  7.110.100\n",
      "  libavresample   4.  0.  0 /  4.  0.  0\n",
      "  libswscale      5.  9.100 /  5.  9.100\n",
      "  libswresample   3.  9.100 /  3.  9.100\n",
      "Unknown attached picture mimetype: image/, skipping.\n",
      "[mp3 @ 0x56015ff2d580] Estimating duration from bitrate, this may be inaccurate\n",
      "Input #0, mp3, from '/var/home/fraser/machine_learning/whisper.cpp/samples/1.m2a':\n",
      "  Metadata:\n",
      "    title           : U.S. Stocks Snap Four-Session Losing Streak\n",
      "    lyrics-ENG      : <p>Plus: <a href=\"https://www.wsj.com/finance/stocks/global-stocks-markets-dow-news-09-25-2023-fb657d6b?st=earxebvnzc3nqj5&amp;reflink=desktopwebshare_permalink\">Amazon shares rise on news the company will invest up to $4 billion in AI</a> company Anthrop\n",
      "                    : <p><br></p>\n",
      "                    : \n",
      "    artist          : The Wall Street Journal\n",
      "    album           : WSJ Minute Briefing\n",
      "    genre           : Podcast\n",
      "    date            : 2018\n",
      "  Duration: 00:01:50.94, start: 0.000000, bitrate: 133 kb/s\n",
      "  Stream #0:0: Audio: mp3, 44100 Hz, mono, fltp, 128 kb/s\n",
      "File '/var/home/fraser/machine_learning/whisper.cpp/samples/1.m2a-output.wav' already exists. Overwrite? [y/N] Stream mapping:\n",
      "  Stream #0:0 -> #0:0 (mp3 (mp3float) -> pcm_s16le (native))\n",
      "Press [q] to stop, [?] for help\n",
      "Output #0, wav, to '/var/home/fraser/machine_learning/whisper.cpp/samples/1.m2a-output.wav':\n",
      "  Metadata:\n",
      "    INAM            : U.S. Stocks Snap Four-Session Losing Streak\n",
      "    lyrics-ENG      : <p>Plus: <a href=\"https://www.wsj.com/finance/stocks/global-stocks-markets-dow-news-09-25-2023-fb657d6b?st=earxebvnzc3nqj5&amp;reflink=desktopwebshare_permalink\">Amazon shares rise on news the company will invest up to $4 billion in AI</a> company Anthrop\n",
      "                    : <p><br></p>\n",
      "                    : \n",
      "    IART            : The Wall Street Journal\n",
      "    IPRD            : WSJ Minute Briefing\n",
      "    IGNR            : Podcast\n",
      "    ICRD            : 2018\n",
      "    ISFT            : Lavf58.76.100\n",
      "  Stream #0:0: Audio: pcm_s16le ([1][0][0][0] / 0x0001), 16000 Hz, mono, s16, 256 kb/s\n",
      "    Metadata:\n",
      "      encoder         : Lavc58.134.100 pcm_s16le\n",
      "size=    3467kB time=00:01:50.94 bitrate= 256.0kbits/s speed=1.15e+03x    \n",
      "video:0kB audio:3467kB subtitle:0kB other streams:0kB global headers:0kB muxing overhead: 0.006197%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "saved: <_io.TextIOWrapper name='/var/home/fraser/machine_learning/whisper.cpp/samples/1.m2a-output.wav.md' mode='a' encoding='UTF-8'>\n",
      "/var/home/fraser/machine_learning/whisper.cpp/samples/4291.m2a\n",
      "/var/home/fraser/machine_learning/whisper.cpp/samples/4291.m2a-output.wav\n",
      "Audio coverted successfully.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ffmpeg version 4.4 Copyright (c) 2000-2021 the FFmpeg developers\n",
      "  built with gcc 9.3.0 (crosstool-NG 1.24.0.133_b0863d8_dirty)\n",
      "  configuration: --prefix=/root/miniconda3/envs/conda_bld/conda-bld/ffmpeg_1635335682798/_h_env_placehold_placehold_placehold_placehold_placehold_placehold_placehold_placehold_placehold_placehold_placehold_placehold_placehold_placehold_placehold_placehold_placehold_placehold_place --cc=/root/miniconda3/envs/conda_bld/conda-bld/ffmpeg_1635335682798/_build_env/bin/x86_64-conda-linux-gnu-cc --disable-doc --disable-openssl --enable-avresample --enable-hardcoded-tables --enable-libfreetype --enable-libopenh264 --enable-pic --enable-pthreads --enable-shared --disable-static --enable-version3 --enable-zlib --enable-libmp3lame\n",
      "  libavutil      56. 70.100 / 56. 70.100\n",
      "  libavcodec     58.134.100 / 58.134.100\n",
      "  libavformat    58. 76.100 / 58. 76.100\n",
      "  libavdevice    58. 13.100 / 58. 13.100\n",
      "  libavfilter     7.110.100 /  7.110.100\n",
      "  libavresample   4.  0.  0 /  4.  0.  0\n",
      "  libswscale      5.  9.100 /  5.  9.100\n",
      "  libswresample   3.  9.100 /  3.  9.100\n",
      "Unknown attached picture mimetype: image/, skipping.\n",
      "[mp3 @ 0x562ae1d33580] Estimating duration from bitrate, this may be inaccurate\n",
      "Input #0, mp3, from '/var/home/fraser/machine_learning/whisper.cpp/samples/4291.m2a':\n",
      "  Metadata:\n",
      "    title           : The U.S. Prepares Major Sanctions on Russia\n",
      "    lyrics-ENG      : <p>Plus: The Biden administration plans to replace China-built cranes amid national security concerns. And defense company BAE Systems reports growing sales as conflicts around the world pump up demand. Luke Vargas hosts.</p>\n",
      "                    : \n",
      "    artist          : The Wall Street Journal\n",
      "    album           : WSJ Minute Briefing\n",
      "    genre           : Podcast\n",
      "    date            : 2018\n",
      "  Duration: 00:02:42.87, start: 0.000000, bitrate: 132 kb/s\n",
      "  Stream #0:0: Audio: mp3, 44100 Hz, stereo, fltp, 128 kb/s\n",
      "File '/var/home/fraser/machine_learning/whisper.cpp/samples/4291.m2a-output.wav' already exists. Overwrite? [y/N] Stream mapping:\n",
      "  Stream #0:0 -> #0:0 (mp3 (mp3float) -> pcm_s16le (native))\n",
      "Press [q] to stop, [?] for help\n",
      "Output #0, wav, to '/var/home/fraser/machine_learning/whisper.cpp/samples/4291.m2a-output.wav':\n",
      "  Metadata:\n",
      "    INAM            : The U.S. Prepares Major Sanctions on Russia\n",
      "    lyrics-ENG      : <p>Plus: The Biden administration plans to replace China-built cranes amid national security concerns. And defense company BAE Systems reports growing sales as conflicts around the world pump up demand. Luke Vargas hosts.</p>\n",
      "                    : \n",
      "    IART            : The Wall Street Journal\n",
      "    IPRD            : WSJ Minute Briefing\n",
      "    IGNR            : Podcast\n",
      "    ICRD            : 2018\n",
      "    ISFT            : Lavf58.76.100\n",
      "  Stream #0:0: Audio: pcm_s16le ([1][0][0][0] / 0x0001), 16000 Hz, mono, s16, 256 kb/s\n",
      "    Metadata:\n",
      "      encoder         : Lavc58.134.100 pcm_s16le\n",
      "size=    5090kB time=00:02:42.87 bitrate= 256.0kbits/s speed= 967x    \n",
      "video:0kB audio:5090kB subtitle:0kB other streams:0kB global headers:0kB muxing overhead: 0.004221%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "saved: <_io.TextIOWrapper name='/var/home/fraser/machine_learning/whisper.cpp/samples/4291.m2a-output.wav.md' mode='a' encoding='UTF-8'>\n",
      "/var/home/fraser/machine_learning/whisper.cpp/samples/4331.m2a\n",
      "/var/home/fraser/machine_learning/whisper.cpp/samples/4331.m2a-output.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ffmpeg version 4.4 Copyright (c) 2000-2021 the FFmpeg developers\n",
      "  built with gcc 9.3.0 (crosstool-NG 1.24.0.133_b0863d8_dirty)\n",
      "  configuration: --prefix=/root/miniconda3/envs/conda_bld/conda-bld/ffmpeg_1635335682798/_h_env_placehold_placehold_placehold_placehold_placehold_placehold_placehold_placehold_placehold_placehold_placehold_placehold_placehold_placehold_placehold_placehold_placehold_placehold_place --cc=/root/miniconda3/envs/conda_bld/conda-bld/ffmpeg_1635335682798/_build_env/bin/x86_64-conda-linux-gnu-cc --disable-doc --disable-openssl --enable-avresample --enable-hardcoded-tables --enable-libfreetype --enable-libopenh264 --enable-pic --enable-pthreads --enable-shared --disable-static --enable-version3 --enable-zlib --enable-libmp3lame\n",
      "  libavutil      56. 70.100 / 56. 70.100\n",
      "  libavcodec     58.134.100 / 58.134.100\n",
      "  libavformat    58. 76.100 / 58. 76.100\n",
      "  libavdevice    58. 13.100 / 58. 13.100\n",
      "  libavfilter     7.110.100 /  7.110.100\n",
      "  libavresample   4.  0.  0 /  4.  0.  0\n",
      "  libswscale      5.  9.100 /  5.  9.100\n",
      "  libswresample   3.  9.100 /  3.  9.100\n",
      "[mp3 @ 0x5584c7bd1580] Estimating duration from bitrate, this may be inaccurate\n",
      "Input #0, mp3, from '/var/home/fraser/machine_learning/whisper.cpp/samples/4331.m2a':\n",
      "  Metadata:\n",
      "    track           : 1\n",
      "    comment         : preroll_1_30000;postroll_1_30000\n",
      "    encoder         : Lavf58.78.100\n",
      "    date            : 2024\n",
      "  Duration: 00:38:40.98, start: 0.000000, bitrate: 128 kb/s\n",
      "  Stream #0:0: Audio: mp3, 44100 Hz, stereo, fltp, 128 kb/s\n",
      "Stream mapping:\n",
      "  Stream #0:0 -> #0:0 (mp3 (mp3float) -> pcm_s16le (native))\n",
      "Press [q] to stop, [?] for help\n",
      "Output #0, wav, to '/var/home/fraser/machine_learning/whisper.cpp/samples/4331.m2a-output.wav':\n",
      "  Metadata:\n",
      "    IPRT            : 1\n",
      "    ICMT            : preroll_1_30000;postroll_1_30000\n",
      "    ICRD            : 2024\n",
      "    ISFT            : Lavf58.76.100\n",
      "  Stream #0:0: Audio: pcm_s16le ([1][0][0][0] / 0x0001), 16000 Hz, mono, s16, 256 kb/s\n",
      "    Metadata:\n",
      "      encoder         : Lavc58.134.100 pcm_s16le\n",
      "size=   72531kB time=00:38:40.97 bitrate= 256.0kbits/s speed=1.09e+03x    \n",
      "video:0kB audio:72531kB subtitle:0kB other streams:0kB global headers:0kB muxing overhead: 0.000194%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Audio coverted successfully.\n",
      "saved: <_io.TextIOWrapper name='/var/home/fraser/machine_learning/whisper.cpp/samples/4331.m2a-output.wav.md' mode='a' encoding='UTF-8'>\n",
      "/var/home/fraser/machine_learning/whisper.cpp/samples/5898.m2a\n",
      "/var/home/fraser/machine_learning/whisper.cpp/samples/5898.m2a-output.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ffmpeg version 4.4 Copyright (c) 2000-2021 the FFmpeg developers\n",
      "  built with gcc 9.3.0 (crosstool-NG 1.24.0.133_b0863d8_dirty)\n",
      "  configuration: --prefix=/root/miniconda3/envs/conda_bld/conda-bld/ffmpeg_1635335682798/_h_env_placehold_placehold_placehold_placehold_placehold_placehold_placehold_placehold_placehold_placehold_placehold_placehold_placehold_placehold_placehold_placehold_placehold_placehold_place --cc=/root/miniconda3/envs/conda_bld/conda-bld/ffmpeg_1635335682798/_build_env/bin/x86_64-conda-linux-gnu-cc --disable-doc --disable-openssl --enable-avresample --enable-hardcoded-tables --enable-libfreetype --enable-libopenh264 --enable-pic --enable-pthreads --enable-shared --disable-static --enable-version3 --enable-zlib --enable-libmp3lame\n",
      "  libavutil      56. 70.100 / 56. 70.100\n",
      "  libavcodec     58.134.100 / 58.134.100\n",
      "  libavformat    58. 76.100 / 58. 76.100\n",
      "  libavdevice    58. 13.100 / 58. 13.100\n",
      "  libavfilter     7.110.100 /  7.110.100\n",
      "  libavresample   4.  0.  0 /  4.  0.  0\n",
      "  libswscale      5.  9.100 /  5.  9.100\n",
      "  libswresample   3.  9.100 /  3.  9.100\n",
      "[mp3 @ 0x55f449828580] Estimating duration from bitrate, this may be inaccurate\n",
      "Input #0, mp3, from '/var/home/fraser/machine_learning/whisper.cpp/samples/5898.m2a':\n",
      "  Metadata:\n",
      "    track           : 1\n",
      "    comment         : preroll_1_30000;postroll_1_30000\n",
      "    encoder         : Lavf60.21.100\n",
      "    date            : 2024\n",
      "  Duration: 00:39:36.75, start: 0.000000, bitrate: 128 kb/s\n",
      "  Stream #0:0: Audio: mp3, 44100 Hz, stereo, fltp, 128 kb/s\n",
      "Stream mapping:\n",
      "  Stream #0:0 -> #0:0 (mp3 (mp3float) -> pcm_s16le (native))\n",
      "Press [q] to stop, [?] for help\n",
      "Output #0, wav, to '/var/home/fraser/machine_learning/whisper.cpp/samples/5898.m2a-output.wav':\n",
      "  Metadata:\n",
      "    IPRT            : 1\n",
      "    ICMT            : preroll_1_30000;postroll_1_30000\n",
      "    ICRD            : 2024\n",
      "    ISFT            : Lavf58.76.100\n",
      "  Stream #0:0: Audio: pcm_s16le ([1][0][0][0] / 0x0001), 16000 Hz, mono, s16, 256 kb/s\n",
      "    Metadata:\n",
      "      encoder         : Lavc58.134.100 pcm_s16le\n",
      "size=   74274kB time=00:39:36.75 bitrate= 256.0kbits/s speed=1.08e+03x    \n",
      "video:0kB audio:74273kB subtitle:0kB other streams:0kB global headers:0kB muxing overhead: 0.000189%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Audio coverted successfully.\n",
      "saved: <_io.TextIOWrapper name='/var/home/fraser/machine_learning/whisper.cpp/samples/5898.m2a-output.wav.md' mode='a' encoding='UTF-8'>\n",
      "/var/home/fraser/machine_learning/whisper.cpp/samples/5879.m2a\n",
      "/var/home/fraser/machine_learning/whisper.cpp/samples/5879.m2a-output.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ffmpeg version 4.4 Copyright (c) 2000-2021 the FFmpeg developers\n",
      "  built with gcc 9.3.0 (crosstool-NG 1.24.0.133_b0863d8_dirty)\n",
      "  configuration: --prefix=/root/miniconda3/envs/conda_bld/conda-bld/ffmpeg_1635335682798/_h_env_placehold_placehold_placehold_placehold_placehold_placehold_placehold_placehold_placehold_placehold_placehold_placehold_placehold_placehold_placehold_placehold_placehold_placehold_place --cc=/root/miniconda3/envs/conda_bld/conda-bld/ffmpeg_1635335682798/_build_env/bin/x86_64-conda-linux-gnu-cc --disable-doc --disable-openssl --enable-avresample --enable-hardcoded-tables --enable-libfreetype --enable-libopenh264 --enable-pic --enable-pthreads --enable-shared --disable-static --enable-version3 --enable-zlib --enable-libmp3lame\n",
      "  libavutil      56. 70.100 / 56. 70.100\n",
      "  libavcodec     58.134.100 / 58.134.100\n",
      "  libavformat    58. 76.100 / 58. 76.100\n",
      "  libavdevice    58. 13.100 / 58. 13.100\n",
      "  libavfilter     7.110.100 /  7.110.100\n",
      "  libavresample   4.  0.  0 /  4.  0.  0\n",
      "  libswscale      5.  9.100 /  5.  9.100\n",
      "  libswresample   3.  9.100 /  3.  9.100\n",
      "[mp3 @ 0x556adddc9580] Estimating duration from bitrate, this may be inaccurate\n",
      "Input #0, mp3, from '/var/home/fraser/machine_learning/whisper.cpp/samples/5879.m2a':\n",
      "  Metadata:\n",
      "    track           : 1\n",
      "    comment         : preroll_1_30000;postroll_1_30000\n",
      "    encoder         : Lavf60.21.100\n",
      "    date            : 2024\n",
      "  Duration: 00:40:19.10, start: 0.000000, bitrate: 128 kb/s\n",
      "  Stream #0:0: Audio: mp3, 44100 Hz, stereo, fltp, 128 kb/s\n",
      "Stream mapping:\n",
      "  Stream #0:0 -> #0:0 (mp3 (mp3float) -> pcm_s16le (native))\n",
      "Press [q] to stop, [?] for help\n",
      "Output #0, wav, to '/var/home/fraser/machine_learning/whisper.cpp/samples/5879.m2a-output.wav':\n",
      "  Metadata:\n",
      "    IPRT            : 1\n",
      "    ICMT            : preroll_1_30000;postroll_1_30000\n",
      "    ICRD            : 2024\n",
      "    ISFT            : Lavf58.76.100\n",
      "  Stream #0:0: Audio: pcm_s16le ([1][0][0][0] / 0x0001), 16000 Hz, mono, s16, 256 kb/s\n",
      "    Metadata:\n",
      "      encoder         : Lavc58.134.100 pcm_s16le\n",
      "[mp3float @ 0x556adddcd880] overread, skip -5 enddists: -2 -21.09e+03x    \n",
      "size=   75597kB time=00:40:19.09 bitrate= 256.0kbits/s speed=1.09e+03x    \n",
      "video:0kB audio:75597kB subtitle:0kB other streams:0kB global headers:0kB muxing overhead: 0.000186%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Audio coverted successfully.\n",
      "saved: <_io.TextIOWrapper name='/var/home/fraser/machine_learning/whisper.cpp/samples/5879.m2a-output.wav.md' mode='a' encoding='UTF-8'>\n",
      "/var/home/fraser/machine_learning/whisper.cpp/samples/5871.m2a\n",
      "/var/home/fraser/machine_learning/whisper.cpp/samples/5871.m2a-output.wav\n",
      "Audio coverted successfully.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ffmpeg version 4.4 Copyright (c) 2000-2021 the FFmpeg developers\n",
      "  built with gcc 9.3.0 (crosstool-NG 1.24.0.133_b0863d8_dirty)\n",
      "  configuration: --prefix=/root/miniconda3/envs/conda_bld/conda-bld/ffmpeg_1635335682798/_h_env_placehold_placehold_placehold_placehold_placehold_placehold_placehold_placehold_placehold_placehold_placehold_placehold_placehold_placehold_placehold_placehold_placehold_placehold_place --cc=/root/miniconda3/envs/conda_bld/conda-bld/ffmpeg_1635335682798/_build_env/bin/x86_64-conda-linux-gnu-cc --disable-doc --disable-openssl --enable-avresample --enable-hardcoded-tables --enable-libfreetype --enable-libopenh264 --enable-pic --enable-pthreads --enable-shared --disable-static --enable-version3 --enable-zlib --enable-libmp3lame\n",
      "  libavutil      56. 70.100 / 56. 70.100\n",
      "  libavcodec     58.134.100 / 58.134.100\n",
      "  libavformat    58. 76.100 / 58. 76.100\n",
      "  libavdevice    58. 13.100 / 58. 13.100\n",
      "  libavfilter     7.110.100 /  7.110.100\n",
      "  libavresample   4.  0.  0 /  4.  0.  0\n",
      "  libswscale      5.  9.100 /  5.  9.100\n",
      "  libswresample   3.  9.100 /  3.  9.100\n",
      "Unknown attached picture mimetype: image/, skipping.\n",
      "[mp3 @ 0x56168dfab580] Estimating duration from bitrate, this may be inaccurate\n",
      "Input #0, mp3, from '/var/home/fraser/machine_learning/whisper.cpp/samples/5871.m2a':\n",
      "  Metadata:\n",
      "    title           : TNB Tech Minute: Rivian Unveils Two, Lower-Priced Electric SUVs\n",
      "    lyrics-ENG      : <p>Plus: Netflix announces boxing match between Mike Tyson and Jake Paul. And we exclusively report that Temu’s push into the U.S. market has meant big money for Meta and Google.  Danny Lewis hosts.</p>\n",
      "                    : \n",
      "    artist          : The Wall Street Journal\n",
      "    album           : WSJ Tech News Briefing\n",
      "    genre           : Podcast\n",
      "    date            : 2019\n",
      "  Duration: 00:01:38.59, start: 0.000000, bitrate: 135 kb/s\n",
      "  Stream #0:0: Audio: mp3, 44100 Hz, stereo, fltp, 128 kb/s\n",
      "Stream mapping:\n",
      "  Stream #0:0 -> #0:0 (mp3 (mp3float) -> pcm_s16le (native))\n",
      "Press [q] to stop, [?] for help\n",
      "Output #0, wav, to '/var/home/fraser/machine_learning/whisper.cpp/samples/5871.m2a-output.wav':\n",
      "  Metadata:\n",
      "    INAM            : TNB Tech Minute: Rivian Unveils Two, Lower-Priced Electric SUVs\n",
      "    lyrics-ENG      : <p>Plus: Netflix announces boxing match between Mike Tyson and Jake Paul. And we exclusively report that Temu’s push into the U.S. market has meant big money for Meta and Google.  Danny Lewis hosts.</p>\n",
      "                    : \n",
      "    IART            : The Wall Street Journal\n",
      "    IPRD            : WSJ Tech News Briefing\n",
      "    IGNR            : Podcast\n",
      "    ICRD            : 2019\n",
      "    ISFT            : Lavf58.76.100\n",
      "  Stream #0:0: Audio: pcm_s16le ([1][0][0][0] / 0x0001), 16000 Hz, mono, s16, 256 kb/s\n",
      "    Metadata:\n",
      "      encoder         : Lavc58.134.100 pcm_s16le\n",
      "size=    3081kB time=00:01:38.58 bitrate= 256.0kbits/s speed= 949x    \n",
      "video:0kB audio:3081kB subtitle:0kB other streams:0kB global headers:0kB muxing overhead: 0.007734%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "saved: <_io.TextIOWrapper name='/var/home/fraser/machine_learning/whisper.cpp/samples/5871.m2a-output.wav.md' mode='a' encoding='UTF-8'>\n",
      "/var/home/fraser/machine_learning/whisper.cpp/samples/1.m2a-output.wav\n",
      "/var/home/fraser/machine_learning/whisper.cpp/samples/1.m2a-output.wav-output.wav\n",
      "Audio coverted successfully.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ffmpeg version 4.4 Copyright (c) 2000-2021 the FFmpeg developers\n",
      "  built with gcc 9.3.0 (crosstool-NG 1.24.0.133_b0863d8_dirty)\n",
      "  configuration: --prefix=/root/miniconda3/envs/conda_bld/conda-bld/ffmpeg_1635335682798/_h_env_placehold_placehold_placehold_placehold_placehold_placehold_placehold_placehold_placehold_placehold_placehold_placehold_placehold_placehold_placehold_placehold_placehold_placehold_place --cc=/root/miniconda3/envs/conda_bld/conda-bld/ffmpeg_1635335682798/_build_env/bin/x86_64-conda-linux-gnu-cc --disable-doc --disable-openssl --enable-avresample --enable-hardcoded-tables --enable-libfreetype --enable-libopenh264 --enable-pic --enable-pthreads --enable-shared --disable-static --enable-version3 --enable-zlib --enable-libmp3lame\n",
      "  libavutil      56. 70.100 / 56. 70.100\n",
      "  libavcodec     58.134.100 / 58.134.100\n",
      "  libavformat    58. 76.100 / 58. 76.100\n",
      "  libavdevice    58. 13.100 / 58. 13.100\n",
      "  libavfilter     7.110.100 /  7.110.100\n",
      "  libavresample   4.  0.  0 /  4.  0.  0\n",
      "  libswscale      5.  9.100 /  5.  9.100\n",
      "  libswresample   3.  9.100 /  3.  9.100\n",
      "Guessed Channel Layout for Input Stream #0.0 : mono\n",
      "Input #0, wav, from '/var/home/fraser/machine_learning/whisper.cpp/samples/1.m2a-output.wav':\n",
      "  Metadata:\n",
      "    artist          : The Wall Street Journal\n",
      "    date            : 2018\n",
      "    genre           : Podcast\n",
      "    title           : U.S. Stocks Snap Four-Session Losing Streak\n",
      "    album           : WSJ Minute Briefing\n",
      "    encoder         : Lavf58.76.100\n",
      "  Duration: 00:01:50.94, bitrate: 256 kb/s\n",
      "  Stream #0:0: Audio: pcm_s16le ([1][0][0][0] / 0x0001), 16000 Hz, mono, s16, 256 kb/s\n",
      "Stream mapping:\n",
      "  Stream #0:0 -> #0:0 (pcm_s16le (native) -> pcm_s16le (native))\n",
      "Press [q] to stop, [?] for help\n",
      "Output #0, wav, to '/var/home/fraser/machine_learning/whisper.cpp/samples/1.m2a-output.wav-output.wav':\n",
      "  Metadata:\n",
      "    IART            : The Wall Street Journal\n",
      "    ICRD            : 2018\n",
      "    IGNR            : Podcast\n",
      "    INAM            : U.S. Stocks Snap Four-Session Losing Streak\n",
      "    IPRD            : WSJ Minute Briefing\n",
      "    ISFT            : Lavf58.76.100\n",
      "  Stream #0:0: Audio: pcm_s16le ([1][0][0][0] / 0x0001), 16000 Hz, mono, s16, 256 kb/s\n",
      "    Metadata:\n",
      "      encoder         : Lavc58.134.100 pcm_s16le\n",
      "size=    3467kB time=00:01:50.84 bitrate= 256.2kbits/s speed=1.74e+04x    \n",
      "video:0kB audio:3467kB subtitle:0kB other streams:0kB global headers:0kB muxing overhead: 0.006197%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "saved: <_io.TextIOWrapper name='/var/home/fraser/machine_learning/whisper.cpp/samples/1.m2a-output.wav-output.wav.md' mode='a' encoding='UTF-8'>\n",
      "/var/home/fraser/machine_learning/whisper.cpp/samples/4291.m2a-output.wav\n",
      "/var/home/fraser/machine_learning/whisper.cpp/samples/4291.m2a-output.wav-output.wav\n",
      "Audio coverted successfully.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ffmpeg version 4.4 Copyright (c) 2000-2021 the FFmpeg developers\n",
      "  built with gcc 9.3.0 (crosstool-NG 1.24.0.133_b0863d8_dirty)\n",
      "  configuration: --prefix=/root/miniconda3/envs/conda_bld/conda-bld/ffmpeg_1635335682798/_h_env_placehold_placehold_placehold_placehold_placehold_placehold_placehold_placehold_placehold_placehold_placehold_placehold_placehold_placehold_placehold_placehold_placehold_placehold_place --cc=/root/miniconda3/envs/conda_bld/conda-bld/ffmpeg_1635335682798/_build_env/bin/x86_64-conda-linux-gnu-cc --disable-doc --disable-openssl --enable-avresample --enable-hardcoded-tables --enable-libfreetype --enable-libopenh264 --enable-pic --enable-pthreads --enable-shared --disable-static --enable-version3 --enable-zlib --enable-libmp3lame\n",
      "  libavutil      56. 70.100 / 56. 70.100\n",
      "  libavcodec     58.134.100 / 58.134.100\n",
      "  libavformat    58. 76.100 / 58. 76.100\n",
      "  libavdevice    58. 13.100 / 58. 13.100\n",
      "  libavfilter     7.110.100 /  7.110.100\n",
      "  libavresample   4.  0.  0 /  4.  0.  0\n",
      "  libswscale      5.  9.100 /  5.  9.100\n",
      "  libswresample   3.  9.100 /  3.  9.100\n",
      "Guessed Channel Layout for Input Stream #0.0 : mono\n",
      "Input #0, wav, from '/var/home/fraser/machine_learning/whisper.cpp/samples/4291.m2a-output.wav':\n",
      "  Metadata:\n",
      "    artist          : The Wall Street Journal\n",
      "    date            : 2018\n",
      "    genre           : Podcast\n",
      "    title           : The U.S. Prepares Major Sanctions on Russia\n",
      "    album           : WSJ Minute Briefing\n",
      "    encoder         : Lavf58.76.100\n",
      "  Duration: 00:02:42.87, bitrate: 256 kb/s\n",
      "  Stream #0:0: Audio: pcm_s16le ([1][0][0][0] / 0x0001), 16000 Hz, mono, s16, 256 kb/s\n",
      "Stream mapping:\n",
      "  Stream #0:0 -> #0:0 (pcm_s16le (native) -> pcm_s16le (native))\n",
      "Press [q] to stop, [?] for help\n",
      "Output #0, wav, to '/var/home/fraser/machine_learning/whisper.cpp/samples/4291.m2a-output.wav-output.wav':\n",
      "  Metadata:\n",
      "    IART            : The Wall Street Journal\n",
      "    ICRD            : 2018\n",
      "    IGNR            : Podcast\n",
      "    INAM            : The U.S. Prepares Major Sanctions on Russia\n",
      "    IPRD            : WSJ Minute Briefing\n",
      "    ISFT            : Lavf58.76.100\n",
      "  Stream #0:0: Audio: pcm_s16le ([1][0][0][0] / 0x0001), 16000 Hz, mono, s16, 256 kb/s\n",
      "    Metadata:\n",
      "      encoder         : Lavc58.134.100 pcm_s16le\n",
      "size=    5090kB time=00:02:42.81 bitrate= 256.1kbits/s speed=1.68e+04x    \n",
      "video:0kB audio:5090kB subtitle:0kB other streams:0kB global headers:0kB muxing overhead: 0.004221%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "saved: <_io.TextIOWrapper name='/var/home/fraser/machine_learning/whisper.cpp/samples/4291.m2a-output.wav-output.wav.md' mode='a' encoding='UTF-8'>\n"
     ]
    }
   ],
   "source": [
    "# iterate over all audio files and transcribe them:\n",
    "for file in files:\n",
    "    audio_file = file\n",
    "    # convert audio file to 16-bit wav format required by whisper\n",
    "    output_file = audio_file + '-output.wav'\n",
    "    print(audio_file)\n",
    "    print(output_file)\n",
    "\n",
    "    # convert audio_file then transcribe to text\n",
    "    # overwrites existing file with same name with yes_command\n",
    "    try:\n",
    "        yes_command = f'echo \"y\" | '\n",
    "        subprocess.run([yes_command + 'ffmpeg' + ' -i ' +  audio_file + ' -ar 16000 -ac 1 -c:a pcm_s16le ' \n",
    "                        + output_file], shell=True, check=True)\n",
    "        print(\"Audio coverted successfully.\")\n",
    "    except subprocess.CalledProcessError as e:\n",
    "        print(f\"Audio convertion failed with error {e.returncode}.\")\n",
    "\n",
    "    # pipeline\n",
    "    pipe = pipeline(\n",
    "        \"automatic-speech-recognition\",\n",
    "        model=model,\n",
    "        tokenizer=processor.tokenizer,\n",
    "        feature_extractor=processor.feature_extractor,\n",
    "        max_new_tokens=128,\n",
    "        chunk_length_s=15,\n",
    "        batch_size=16,\n",
    "        torch_dtype=torch_dtype,\n",
    "        device=device\n",
    "    )\n",
    "    result_local = pipe(output_file)\n",
    "\n",
    "    # save transcript as a .md file\n",
    "    saved_txt=result_local[\"text\"]\n",
    "    f = open(output_file + \".md\", \"a\")\n",
    "    f.write(saved_txt)\n",
    "    f.close()\n",
    "    print(\"saved:\", f)\n",
    "        "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "py310",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
