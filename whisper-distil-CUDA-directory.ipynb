{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Modification of whisper-distil.ipynb to handle bulk transcriptions of an entire directory. Added a file renaming function to remove spaces from any audio filename (as ffmpeg will cut off after the space).\n",
    "\n",
    "CAUTION: MAKE SURE TO BACKUP AUDIO FILES IF THEY HAVE SPACES IN THEIR NAMES AS THEY WILL BE RENAMED (AND THE METADATA ALTERED). For file names without spaces, the original file is not renamed and a copy is made in a compatible audio format."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'2.2.1+cu121'"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "torch.__version__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# need cuda for vastly faster transcription\n",
    "#47 seconds for a full 30 min podcast! Insanely fast\n",
    "torch.cuda.is_available()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda:0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n"
     ]
    }
   ],
   "source": [
    "# https://github.com/huggingface/distil-whisper\n",
    "# conda activate py310\n",
    "import torch\n",
    "import subprocess\n",
    "import os\n",
    "import glob\n",
    "import shutil\n",
    "from transformers import AutoModelForSpeechSeq2Seq, AutoProcessor, pipeline\n",
    "\n",
    "device = \"cuda:0\" if torch.cuda.is_available() else \"cpu\"\n",
    "torch_dtype = torch.float16 if torch.cuda.is_available() else torch.float32\n",
    "print(device)\n",
    "\n",
    "# biggest model for highest quality\n",
    "model_id = \"distil-whisper/distil-large-v2\"\n",
    "model = AutoModelForSpeechSeq2Seq.from_pretrained(\n",
    "    model_id, \n",
    "    torch_dtype=torch_dtype, \n",
    "    low_cpu_mem_usage=True, \n",
    "    use_safetensors=True,\n",
    "    attn_implementation=\"flash_attention_2\")        # updated\n",
    "model.to(device)\n",
    "processor = AutoProcessor.from_pretrained(model_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# set podcasts=True to copy all downloaded podcasts to the whisper.cpp/samples directory\n",
    "# example file location is from great Gnome Podcast app:  https://apps.gnome.org/en-GB/Podcasts/ \n",
    "podcasts = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# rename all audio files with spaces in their name\n",
    "# poe.com assisted code\n",
    "# Specify the directory where the files are located\n",
    "directory = '/var/home/fraser/machine_learning/whisper.cpp/samples/'\n",
    "#directory = '/var/home/fraser/Music/Voice_Memos/'\n",
    "\n",
    "if podcasts:\n",
    "    # copy podcast from subdirectories with spaces to whisper sample directory\n",
    "    source_directory = '/var/home/fraser/.var/app/org.gnome.Podcasts/data/gnome-podcasts/Downloads/'\n",
    "    # Traverse the source directory and its subdirectories\n",
    "    for root, directories, files in os.walk(source_directory):\n",
    "        for file in files:\n",
    "            source_path = os.path.join(root, file)\n",
    "            destination_path = os.path.join(directory, file)\n",
    "            # Copy the file to the destination directory\n",
    "            shutil.copy2(source_path, destination_path)\n",
    "\n",
    "# Get a list of all audio files, .m4a, .mp3, and .wav files, in the directory\n",
    "# added *.m2a for podcasts\n",
    "files = glob.glob(os.path.join(directory, '*.m4a')) + \\\n",
    "        glob.glob(os.path.join(directory, '*.mp3')) + \\\n",
    "        glob.glob(os.path.join(directory, '*.m2a')) + \\\n",
    "        glob.glob(os.path.join(directory, '*.ogg')) + \\\n",
    "        glob.glob(os.path.join(directory, '*.wav'))\n",
    "\n",
    "# Iterate over the files (use this approach also for directory transcription)\n",
    "# CAUTION: this overwrites files with spaces in their names such as 'Track 11.wav' to 'Track-11.wav' \n",
    "# by overwriting the file, it permits processing but alters the metadata to date file saved=today\n",
    "for file in files:\n",
    "    # If the file name contains a space\n",
    "    if ' ' in file:\n",
    "        # Replace the spaces with hyphens\n",
    "        new_name = file.replace(' ', '-')\n",
    "        # Rename the file\n",
    "        os.rename(file, new_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/var/home/fraser/machine_learning/whisper.cpp/samples/1.m2a\n",
      "/var/home/fraser/machine_learning/whisper.cpp/samples/1.m2a-output.wav\n",
      "Audio coverted successfully.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ffmpeg version 4.4 Copyright (c) 2000-2021 the FFmpeg developers\n",
      "  built with gcc 9.3.0 (crosstool-NG 1.24.0.133_b0863d8_dirty)\n",
      "  configuration: --prefix=/root/miniconda3/envs/conda_bld/conda-bld/ffmpeg_1635335682798/_h_env_placehold_placehold_placehold_placehold_placehold_placehold_placehold_placehold_placehold_placehold_placehold_placehold_placehold_placehold_placehold_placehold_placehold_placehold_place --cc=/root/miniconda3/envs/conda_bld/conda-bld/ffmpeg_1635335682798/_build_env/bin/x86_64-conda-linux-gnu-cc --disable-doc --disable-openssl --enable-avresample --enable-hardcoded-tables --enable-libfreetype --enable-libopenh264 --enable-pic --enable-pthreads --enable-shared --disable-static --enable-version3 --enable-zlib --enable-libmp3lame\n",
      "  libavutil      56. 70.100 / 56. 70.100\n",
      "  libavcodec     58.134.100 / 58.134.100\n",
      "  libavformat    58. 76.100 / 58. 76.100\n",
      "  libavdevice    58. 13.100 / 58. 13.100\n",
      "  libavfilter     7.110.100 /  7.110.100\n",
      "  libavresample   4.  0.  0 /  4.  0.  0\n",
      "  libswscale      5.  9.100 /  5.  9.100\n",
      "  libswresample   3.  9.100 /  3.  9.100\n",
      "Unknown attached picture mimetype: image/, skipping.\n",
      "[mp3 @ 0x55ee5e873580] Estimating duration from bitrate, this may be inaccurate\n",
      "Input #0, mp3, from '/var/home/fraser/machine_learning/whisper.cpp/samples/1.m2a':\n",
      "  Metadata:\n",
      "    title           : U.S. Stocks Snap Four-Session Losing Streak\n",
      "    lyrics-ENG      : <p>Plus: <a href=\"https://www.wsj.com/finance/stocks/global-stocks-markets-dow-news-09-25-2023-fb657d6b?st=earxebvnzc3nqj5&amp;reflink=desktopwebshare_permalink\">Amazon shares rise on news the company will invest up to $4 billion in AI</a> company Anthrop\n",
      "                    : <p><br></p>\n",
      "                    : \n",
      "    artist          : The Wall Street Journal\n",
      "    album           : WSJ Minute Briefing\n",
      "    genre           : Podcast\n",
      "    date            : 2018\n",
      "  Duration: 00:01:50.94, start: 0.000000, bitrate: 133 kb/s\n",
      "  Stream #0:0: Audio: mp3, 44100 Hz, mono, fltp, 128 kb/s\n",
      "Stream mapping:\n",
      "  Stream #0:0 -> #0:0 (mp3 (mp3float) -> pcm_s16le (native))\n",
      "Press [q] to stop, [?] for help\n",
      "Output #0, wav, to '/var/home/fraser/machine_learning/whisper.cpp/samples/1.m2a-output.wav':\n",
      "  Metadata:\n",
      "    INAM            : U.S. Stocks Snap Four-Session Losing Streak\n",
      "    lyrics-ENG      : <p>Plus: <a href=\"https://www.wsj.com/finance/stocks/global-stocks-markets-dow-news-09-25-2023-fb657d6b?st=earxebvnzc3nqj5&amp;reflink=desktopwebshare_permalink\">Amazon shares rise on news the company will invest up to $4 billion in AI</a> company Anthrop\n",
      "                    : <p><br></p>\n",
      "                    : \n",
      "    IART            : The Wall Street Journal\n",
      "    IPRD            : WSJ Minute Briefing\n",
      "    IGNR            : Podcast\n",
      "    ICRD            : 2018\n",
      "    ISFT            : Lavf58.76.100\n",
      "  Stream #0:0: Audio: pcm_s16le ([1][0][0][0] / 0x0001), 16000 Hz, mono, s16, 256 kb/s\n",
      "    Metadata:\n",
      "      encoder         : Lavc58.134.100 pcm_s16le\n",
      "size=    3467kB time=00:01:50.94 bitrate= 256.0kbits/s speed=1.37e+03x    \n",
      "video:0kB audio:3467kB subtitle:0kB other streams:0kB global headers:0kB muxing overhead: 0.006197%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "saved: <_io.TextIOWrapper name='/var/home/fraser/machine_learning/whisper.cpp/samples/1.m2a-output.wav.md' mode='a' encoding='UTF-8'>\n",
      "/var/home/fraser/machine_learning/whisper.cpp/samples/4291.m2a\n",
      "/var/home/fraser/machine_learning/whisper.cpp/samples/4291.m2a-output.wav\n",
      "Audio coverted successfully.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ffmpeg version 4.4 Copyright (c) 2000-2021 the FFmpeg developers\n",
      "  built with gcc 9.3.0 (crosstool-NG 1.24.0.133_b0863d8_dirty)\n",
      "  configuration: --prefix=/root/miniconda3/envs/conda_bld/conda-bld/ffmpeg_1635335682798/_h_env_placehold_placehold_placehold_placehold_placehold_placehold_placehold_placehold_placehold_placehold_placehold_placehold_placehold_placehold_placehold_placehold_placehold_placehold_place --cc=/root/miniconda3/envs/conda_bld/conda-bld/ffmpeg_1635335682798/_build_env/bin/x86_64-conda-linux-gnu-cc --disable-doc --disable-openssl --enable-avresample --enable-hardcoded-tables --enable-libfreetype --enable-libopenh264 --enable-pic --enable-pthreads --enable-shared --disable-static --enable-version3 --enable-zlib --enable-libmp3lame\n",
      "  libavutil      56. 70.100 / 56. 70.100\n",
      "  libavcodec     58.134.100 / 58.134.100\n",
      "  libavformat    58. 76.100 / 58. 76.100\n",
      "  libavdevice    58. 13.100 / 58. 13.100\n",
      "  libavfilter     7.110.100 /  7.110.100\n",
      "  libavresample   4.  0.  0 /  4.  0.  0\n",
      "  libswscale      5.  9.100 /  5.  9.100\n",
      "  libswresample   3.  9.100 /  3.  9.100\n",
      "Unknown attached picture mimetype: image/, skipping.\n",
      "[mp3 @ 0x556882fd0580] Estimating duration from bitrate, this may be inaccurate\n",
      "Input #0, mp3, from '/var/home/fraser/machine_learning/whisper.cpp/samples/4291.m2a':\n",
      "  Metadata:\n",
      "    title           : The U.S. Prepares Major Sanctions on Russia\n",
      "    lyrics-ENG      : <p>Plus: The Biden administration plans to replace China-built cranes amid national security concerns. And defense company BAE Systems reports growing sales as conflicts around the world pump up demand. Luke Vargas hosts.</p>\n",
      "                    : \n",
      "    artist          : The Wall Street Journal\n",
      "    album           : WSJ Minute Briefing\n",
      "    genre           : Podcast\n",
      "    date            : 2018\n",
      "  Duration: 00:02:42.87, start: 0.000000, bitrate: 132 kb/s\n",
      "  Stream #0:0: Audio: mp3, 44100 Hz, stereo, fltp, 128 kb/s\n",
      "Stream mapping:\n",
      "  Stream #0:0 -> #0:0 (mp3 (mp3float) -> pcm_s16le (native))\n",
      "Press [q] to stop, [?] for help\n",
      "Output #0, wav, to '/var/home/fraser/machine_learning/whisper.cpp/samples/4291.m2a-output.wav':\n",
      "  Metadata:\n",
      "    INAM            : The U.S. Prepares Major Sanctions on Russia\n",
      "    lyrics-ENG      : <p>Plus: The Biden administration plans to replace China-built cranes amid national security concerns. And defense company BAE Systems reports growing sales as conflicts around the world pump up demand. Luke Vargas hosts.</p>\n",
      "                    : \n",
      "    IART            : The Wall Street Journal\n",
      "    IPRD            : WSJ Minute Briefing\n",
      "    IGNR            : Podcast\n",
      "    ICRD            : 2018\n",
      "    ISFT            : Lavf58.76.100\n",
      "  Stream #0:0: Audio: pcm_s16le ([1][0][0][0] / 0x0001), 16000 Hz, mono, s16, 256 kb/s\n",
      "    Metadata:\n",
      "      encoder         : Lavc58.134.100 pcm_s16le\n",
      "size=    5090kB time=00:02:42.87 bitrate= 256.0kbits/s speed= 982x    \n",
      "video:0kB audio:5090kB subtitle:0kB other streams:0kB global headers:0kB muxing overhead: 0.004221%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "saved: <_io.TextIOWrapper name='/var/home/fraser/machine_learning/whisper.cpp/samples/4291.m2a-output.wav.md' mode='a' encoding='UTF-8'>\n",
      "/var/home/fraser/machine_learning/whisper.cpp/samples/4331.m2a\n",
      "/var/home/fraser/machine_learning/whisper.cpp/samples/4331.m2a-output.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ffmpeg version 4.4 Copyright (c) 2000-2021 the FFmpeg developers\n",
      "  built with gcc 9.3.0 (crosstool-NG 1.24.0.133_b0863d8_dirty)\n",
      "  configuration: --prefix=/root/miniconda3/envs/conda_bld/conda-bld/ffmpeg_1635335682798/_h_env_placehold_placehold_placehold_placehold_placehold_placehold_placehold_placehold_placehold_placehold_placehold_placehold_placehold_placehold_placehold_placehold_placehold_placehold_place --cc=/root/miniconda3/envs/conda_bld/conda-bld/ffmpeg_1635335682798/_build_env/bin/x86_64-conda-linux-gnu-cc --disable-doc --disable-openssl --enable-avresample --enable-hardcoded-tables --enable-libfreetype --enable-libopenh264 --enable-pic --enable-pthreads --enable-shared --disable-static --enable-version3 --enable-zlib --enable-libmp3lame\n",
      "  libavutil      56. 70.100 / 56. 70.100\n",
      "  libavcodec     58.134.100 / 58.134.100\n",
      "  libavformat    58. 76.100 / 58. 76.100\n",
      "  libavdevice    58. 13.100 / 58. 13.100\n",
      "  libavfilter     7.110.100 /  7.110.100\n",
      "  libavresample   4.  0.  0 /  4.  0.  0\n",
      "  libswscale      5.  9.100 /  5.  9.100\n",
      "  libswresample   3.  9.100 /  3.  9.100\n",
      "[mp3 @ 0x55a6d27c1580] Estimating duration from bitrate, this may be inaccurate\n",
      "Input #0, mp3, from '/var/home/fraser/machine_learning/whisper.cpp/samples/4331.m2a':\n",
      "  Metadata:\n",
      "    track           : 1\n",
      "    comment         : preroll_1_30000;postroll_1_30000\n",
      "    encoder         : Lavf58.78.100\n",
      "    date            : 2024\n",
      "  Duration: 00:38:40.98, start: 0.000000, bitrate: 128 kb/s\n",
      "  Stream #0:0: Audio: mp3, 44100 Hz, stereo, fltp, 128 kb/s\n",
      "Stream mapping:\n",
      "  Stream #0:0 -> #0:0 (mp3 (mp3float) -> pcm_s16le (native))\n",
      "Press [q] to stop, [?] for help\n",
      "Output #0, wav, to '/var/home/fraser/machine_learning/whisper.cpp/samples/4331.m2a-output.wav':\n",
      "  Metadata:\n",
      "    IPRT            : 1\n",
      "    ICMT            : preroll_1_30000;postroll_1_30000\n",
      "    ICRD            : 2024\n",
      "    ISFT            : Lavf58.76.100\n",
      "  Stream #0:0: Audio: pcm_s16le ([1][0][0][0] / 0x0001), 16000 Hz, mono, s16, 256 kb/s\n",
      "    Metadata:\n",
      "      encoder         : Lavc58.134.100 pcm_s16le\n",
      "size=   72531kB time=00:38:40.97 bitrate= 256.0kbits/s speed=1.08e+03x    \n",
      "video:0kB audio:72531kB subtitle:0kB other streams:0kB global headers:0kB muxing overhead: 0.000194%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Audio coverted successfully.\n",
      "saved: <_io.TextIOWrapper name='/var/home/fraser/machine_learning/whisper.cpp/samples/4331.m2a-output.wav.md' mode='a' encoding='UTF-8'>\n",
      "/var/home/fraser/machine_learning/whisper.cpp/samples/5898.m2a\n",
      "/var/home/fraser/machine_learning/whisper.cpp/samples/5898.m2a-output.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ffmpeg version 4.4 Copyright (c) 2000-2021 the FFmpeg developers\n",
      "  built with gcc 9.3.0 (crosstool-NG 1.24.0.133_b0863d8_dirty)\n",
      "  configuration: --prefix=/root/miniconda3/envs/conda_bld/conda-bld/ffmpeg_1635335682798/_h_env_placehold_placehold_placehold_placehold_placehold_placehold_placehold_placehold_placehold_placehold_placehold_placehold_placehold_placehold_placehold_placehold_placehold_placehold_place --cc=/root/miniconda3/envs/conda_bld/conda-bld/ffmpeg_1635335682798/_build_env/bin/x86_64-conda-linux-gnu-cc --disable-doc --disable-openssl --enable-avresample --enable-hardcoded-tables --enable-libfreetype --enable-libopenh264 --enable-pic --enable-pthreads --enable-shared --disable-static --enable-version3 --enable-zlib --enable-libmp3lame\n",
      "  libavutil      56. 70.100 / 56. 70.100\n",
      "  libavcodec     58.134.100 / 58.134.100\n",
      "  libavformat    58. 76.100 / 58. 76.100\n",
      "  libavdevice    58. 13.100 / 58. 13.100\n",
      "  libavfilter     7.110.100 /  7.110.100\n",
      "  libavresample   4.  0.  0 /  4.  0.  0\n",
      "  libswscale      5.  9.100 /  5.  9.100\n",
      "  libswresample   3.  9.100 /  3.  9.100\n",
      "[mp3 @ 0x55c49f565580] Estimating duration from bitrate, this may be inaccurate\n",
      "Input #0, mp3, from '/var/home/fraser/machine_learning/whisper.cpp/samples/5898.m2a':\n",
      "  Metadata:\n",
      "    track           : 1\n",
      "    comment         : preroll_1_30000;postroll_1_30000\n",
      "    encoder         : Lavf60.21.100\n",
      "    date            : 2024\n",
      "  Duration: 00:39:36.75, start: 0.000000, bitrate: 128 kb/s\n",
      "  Stream #0:0: Audio: mp3, 44100 Hz, stereo, fltp, 128 kb/s\n",
      "Stream mapping:\n",
      "  Stream #0:0 -> #0:0 (mp3 (mp3float) -> pcm_s16le (native))\n",
      "Press [q] to stop, [?] for help\n",
      "Output #0, wav, to '/var/home/fraser/machine_learning/whisper.cpp/samples/5898.m2a-output.wav':\n",
      "  Metadata:\n",
      "    IPRT            : 1\n",
      "    ICMT            : preroll_1_30000;postroll_1_30000\n",
      "    ICRD            : 2024\n",
      "    ISFT            : Lavf58.76.100\n",
      "  Stream #0:0: Audio: pcm_s16le ([1][0][0][0] / 0x0001), 16000 Hz, mono, s16, 256 kb/s\n",
      "    Metadata:\n",
      "      encoder         : Lavc58.134.100 pcm_s16le\n",
      "size=   74274kB time=00:39:36.75 bitrate= 256.0kbits/s speed= 815x    \n",
      "video:0kB audio:74273kB subtitle:0kB other streams:0kB global headers:0kB muxing overhead: 0.000189%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Audio coverted successfully.\n",
      "saved: <_io.TextIOWrapper name='/var/home/fraser/machine_learning/whisper.cpp/samples/5898.m2a-output.wav.md' mode='a' encoding='UTF-8'>\n",
      "/var/home/fraser/machine_learning/whisper.cpp/samples/5879.m2a\n",
      "/var/home/fraser/machine_learning/whisper.cpp/samples/5879.m2a-output.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ffmpeg version 4.4 Copyright (c) 2000-2021 the FFmpeg developers\n",
      "  built with gcc 9.3.0 (crosstool-NG 1.24.0.133_b0863d8_dirty)\n",
      "  configuration: --prefix=/root/miniconda3/envs/conda_bld/conda-bld/ffmpeg_1635335682798/_h_env_placehold_placehold_placehold_placehold_placehold_placehold_placehold_placehold_placehold_placehold_placehold_placehold_placehold_placehold_placehold_placehold_placehold_placehold_place --cc=/root/miniconda3/envs/conda_bld/conda-bld/ffmpeg_1635335682798/_build_env/bin/x86_64-conda-linux-gnu-cc --disable-doc --disable-openssl --enable-avresample --enable-hardcoded-tables --enable-libfreetype --enable-libopenh264 --enable-pic --enable-pthreads --enable-shared --disable-static --enable-version3 --enable-zlib --enable-libmp3lame\n",
      "  libavutil      56. 70.100 / 56. 70.100\n",
      "  libavcodec     58.134.100 / 58.134.100\n",
      "  libavformat    58. 76.100 / 58. 76.100\n",
      "  libavdevice    58. 13.100 / 58. 13.100\n",
      "  libavfilter     7.110.100 /  7.110.100\n",
      "  libavresample   4.  0.  0 /  4.  0.  0\n",
      "  libswscale      5.  9.100 /  5.  9.100\n",
      "  libswresample   3.  9.100 /  3.  9.100\n",
      "[mp3 @ 0x562e4cd7b580] Estimating duration from bitrate, this may be inaccurate\n",
      "Input #0, mp3, from '/var/home/fraser/machine_learning/whisper.cpp/samples/5879.m2a':\n",
      "  Metadata:\n",
      "    track           : 1\n",
      "    comment         : preroll_1_30000;postroll_1_30000\n",
      "    encoder         : Lavf60.21.100\n",
      "    date            : 2024\n",
      "  Duration: 00:40:19.10, start: 0.000000, bitrate: 128 kb/s\n",
      "  Stream #0:0: Audio: mp3, 44100 Hz, stereo, fltp, 128 kb/s\n",
      "Stream mapping:\n",
      "  Stream #0:0 -> #0:0 (mp3 (mp3float) -> pcm_s16le (native))\n",
      "Press [q] to stop, [?] for help\n",
      "Output #0, wav, to '/var/home/fraser/machine_learning/whisper.cpp/samples/5879.m2a-output.wav':\n",
      "  Metadata:\n",
      "    IPRT            : 1\n",
      "    ICMT            : preroll_1_30000;postroll_1_30000\n",
      "    ICRD            : 2024\n",
      "    ISFT            : Lavf58.76.100\n",
      "  Stream #0:0: Audio: pcm_s16le ([1][0][0][0] / 0x0001), 16000 Hz, mono, s16, 256 kb/s\n",
      "    Metadata:\n",
      "      encoder         : Lavc58.134.100 pcm_s16le\n",
      "[mp3float @ 0x562e4cd7f880] overread, skip -5 enddists: -2 -2 814x    \n",
      "size=   75597kB time=00:40:19.09 bitrate= 256.0kbits/s speed= 809x    \n",
      "video:0kB audio:75597kB subtitle:0kB other streams:0kB global headers:0kB muxing overhead: 0.000186%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Audio coverted successfully.\n",
      "saved: <_io.TextIOWrapper name='/var/home/fraser/machine_learning/whisper.cpp/samples/5879.m2a-output.wav.md' mode='a' encoding='UTF-8'>\n",
      "/var/home/fraser/machine_learning/whisper.cpp/samples/5871.m2a\n",
      "/var/home/fraser/machine_learning/whisper.cpp/samples/5871.m2a-output.wav\n",
      "Audio coverted successfully.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ffmpeg version 4.4 Copyright (c) 2000-2021 the FFmpeg developers\n",
      "  built with gcc 9.3.0 (crosstool-NG 1.24.0.133_b0863d8_dirty)\n",
      "  configuration: --prefix=/root/miniconda3/envs/conda_bld/conda-bld/ffmpeg_1635335682798/_h_env_placehold_placehold_placehold_placehold_placehold_placehold_placehold_placehold_placehold_placehold_placehold_placehold_placehold_placehold_placehold_placehold_placehold_placehold_place --cc=/root/miniconda3/envs/conda_bld/conda-bld/ffmpeg_1635335682798/_build_env/bin/x86_64-conda-linux-gnu-cc --disable-doc --disable-openssl --enable-avresample --enable-hardcoded-tables --enable-libfreetype --enable-libopenh264 --enable-pic --enable-pthreads --enable-shared --disable-static --enable-version3 --enable-zlib --enable-libmp3lame\n",
      "  libavutil      56. 70.100 / 56. 70.100\n",
      "  libavcodec     58.134.100 / 58.134.100\n",
      "  libavformat    58. 76.100 / 58. 76.100\n",
      "  libavdevice    58. 13.100 / 58. 13.100\n",
      "  libavfilter     7.110.100 /  7.110.100\n",
      "  libavresample   4.  0.  0 /  4.  0.  0\n",
      "  libswscale      5.  9.100 /  5.  9.100\n",
      "  libswresample   3.  9.100 /  3.  9.100\n",
      "Unknown attached picture mimetype: image/, skipping.\n",
      "[mp3 @ 0x55fe0a7e0580] Estimating duration from bitrate, this may be inaccurate\n",
      "Input #0, mp3, from '/var/home/fraser/machine_learning/whisper.cpp/samples/5871.m2a':\n",
      "  Metadata:\n",
      "    title           : TNB Tech Minute: Rivian Unveils Two, Lower-Priced Electric SUVs\n",
      "    lyrics-ENG      : <p>Plus: Netflix announces boxing match between Mike Tyson and Jake Paul. And we exclusively report that Temu’s push into the U.S. market has meant big money for Meta and Google.  Danny Lewis hosts.</p>\n",
      "                    : \n",
      "    artist          : The Wall Street Journal\n",
      "    album           : WSJ Tech News Briefing\n",
      "    genre           : Podcast\n",
      "    date            : 2019\n",
      "  Duration: 00:01:38.59, start: 0.000000, bitrate: 135 kb/s\n",
      "  Stream #0:0: Audio: mp3, 44100 Hz, stereo, fltp, 128 kb/s\n",
      "Stream mapping:\n",
      "  Stream #0:0 -> #0:0 (mp3 (mp3float) -> pcm_s16le (native))\n",
      "Press [q] to stop, [?] for help\n",
      "Output #0, wav, to '/var/home/fraser/machine_learning/whisper.cpp/samples/5871.m2a-output.wav':\n",
      "  Metadata:\n",
      "    INAM            : TNB Tech Minute: Rivian Unveils Two, Lower-Priced Electric SUVs\n",
      "    lyrics-ENG      : <p>Plus: Netflix announces boxing match between Mike Tyson and Jake Paul. And we exclusively report that Temu’s push into the U.S. market has meant big money for Meta and Google.  Danny Lewis hosts.</p>\n",
      "                    : \n",
      "    IART            : The Wall Street Journal\n",
      "    IPRD            : WSJ Tech News Briefing\n",
      "    IGNR            : Podcast\n",
      "    ICRD            : 2019\n",
      "    ISFT            : Lavf58.76.100\n",
      "  Stream #0:0: Audio: pcm_s16le ([1][0][0][0] / 0x0001), 16000 Hz, mono, s16, 256 kb/s\n",
      "    Metadata:\n",
      "      encoder         : Lavc58.134.100 pcm_s16le\n",
      "size=    3081kB time=00:01:38.58 bitrate= 256.0kbits/s speed= 744x    \n",
      "video:0kB audio:3081kB subtitle:0kB other streams:0kB global headers:0kB muxing overhead: 0.007734%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "saved: <_io.TextIOWrapper name='/var/home/fraser/machine_learning/whisper.cpp/samples/5871.m2a-output.wav.md' mode='a' encoding='UTF-8'>\n"
     ]
    }
   ],
   "source": [
    "# iterate over all audio files and transcribe them:\n",
    "for file in files:\n",
    "    audio_file = file\n",
    "    # convert audio file to 16-bit wav format required by whisper\n",
    "    output_file = audio_file + '-output.wav'\n",
    "    print(audio_file)\n",
    "    print(output_file)\n",
    "\n",
    "    # convert audio_file then transcribe to text\n",
    "    # overwrites existing file with same name with yes_command\n",
    "    try:\n",
    "        yes_command = f'echo \"y\" | '\n",
    "        subprocess.run([yes_command + 'ffmpeg' + ' -i ' +  audio_file + ' -ar 16000 -ac 1 -c:a pcm_s16le ' \n",
    "                        + output_file], shell=True, check=True)\n",
    "        print(\"Audio coverted successfully.\")\n",
    "    except subprocess.CalledProcessError as e:\n",
    "        print(f\"Audio convertion failed with error {e.returncode}.\")\n",
    "\n",
    "    # pipeline\n",
    "    pipe = pipeline(\n",
    "        \"automatic-speech-recognition\",\n",
    "        model=model,\n",
    "        tokenizer=processor.tokenizer,\n",
    "        feature_extractor=processor.feature_extractor,\n",
    "        max_new_tokens=128,\n",
    "        chunk_length_s=15,\n",
    "        batch_size=16,\n",
    "        torch_dtype=torch_dtype,\n",
    "        device=device\n",
    "    )\n",
    "    result_local = pipe(output_file)\n",
    "\n",
    "    # save transcript as a .md file\n",
    "    saved_txt=result_local[\"text\"]\n",
    "    f = open(output_file + \".md\", \"a\")\n",
    "    f.write(saved_txt)\n",
    "    f.close()\n",
    "    print(\"saved:\", f)\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Combined 6 Markdown files into podcast_transcripts.md\n"
     ]
    }
   ],
   "source": [
    "# helper utility to combine all transcripts into one file (for ease of scanning podcasts)\n",
    "# ai assisted\n",
    "def combine_markdown_files(output_file_path, input_directory):\n",
    "    markdown_files = glob.glob(input_directory + '*.md')\n",
    "\n",
    "    with open(output_file_path, 'w') as output_file:\n",
    "        for file_path in markdown_files:\n",
    "            file_name = os.path.basename(file_path)\n",
    "            with open(file_path, 'r') as input_file:\n",
    "                output_file.write(f\"## {file_name}\\n\\n\")\n",
    "                output_file.write(input_file.read())\n",
    "                output_file.write('\\n\\n')  # Add newline between files\n",
    "\n",
    "    print(f\"Combined {len(markdown_files)} Markdown files into {output_file_path}\")\n",
    "\n",
    "# saves combined markdown files into directory of Jupyter notebook (not the input directory)\n",
    "combine_markdown_files('podcast_transcripts.md', directory)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "py310",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
