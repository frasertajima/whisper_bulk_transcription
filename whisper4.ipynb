{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/frasertajima/whisper_bulk_transcription/blob/main/whisper4.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1nu7s8ajsV-T",
        "outputId": "29dc9b55-ca3c-4560-ac7c-930268f239f8"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting git+https://github.com/openai/whisper.git\n",
            "  Cloning https://github.com/openai/whisper.git to /tmp/pip-req-build-66fbrnld\n",
            "  Running command git clone -q https://github.com/openai/whisper.git /tmp/pip-req-build-66fbrnld\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (from whisper==1.0) (1.21.6)\n",
            "Requirement already satisfied: torch in /usr/local/lib/python3.7/dist-packages (from whisper==1.0) (1.12.1+cu113)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.7/dist-packages (from whisper==1.0) (4.64.1)\n",
            "Requirement already satisfied: more-itertools in /usr/local/lib/python3.7/dist-packages (from whisper==1.0) (8.14.0)\n",
            "Collecting transformers>=4.19.0\n",
            "  Downloading transformers-4.22.2-py3-none-any.whl (4.9 MB)\n",
            "\u001b[K     |████████████████████████████████| 4.9 MB 32.3 MB/s \n",
            "\u001b[?25hCollecting ffmpeg-python==0.2.0\n",
            "  Downloading ffmpeg_python-0.2.0-py3-none-any.whl (25 kB)\n",
            "Requirement already satisfied: future in /usr/local/lib/python3.7/dist-packages (from ffmpeg-python==0.2.0->whisper==1.0) (0.16.0)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.7/dist-packages (from transformers>=4.19.0->whisper==1.0) (21.3)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.7/dist-packages (from transformers>=4.19.0->whisper==1.0) (2022.6.2)\n",
            "Collecting huggingface-hub<1.0,>=0.9.0\n",
            "  Downloading huggingface_hub-0.10.0-py3-none-any.whl (163 kB)\n",
            "\u001b[K     |████████████████████████████████| 163 kB 56.9 MB/s \n",
            "\u001b[?25hRequirement already satisfied: filelock in /usr/local/lib/python3.7/dist-packages (from transformers>=4.19.0->whisper==1.0) (3.8.0)\n",
            "Requirement already satisfied: importlib-metadata in /usr/local/lib/python3.7/dist-packages (from transformers>=4.19.0->whisper==1.0) (4.12.0)\n",
            "Collecting tokenizers!=0.11.3,<0.13,>=0.11.1\n",
            "  Downloading tokenizers-0.12.1-cp37-cp37m-manylinux_2_12_x86_64.manylinux2010_x86_64.whl (6.6 MB)\n",
            "\u001b[K     |████████████████████████████████| 6.6 MB 56.8 MB/s \n",
            "\u001b[?25hRequirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from transformers>=4.19.0->whisper==1.0) (2.23.0)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.7/dist-packages (from transformers>=4.19.0->whisper==1.0) (6.0)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.7/dist-packages (from huggingface-hub<1.0,>=0.9.0->transformers>=4.19.0->whisper==1.0) (4.1.1)\n",
            "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging>=20.0->transformers>=4.19.0->whisper==1.0) (3.0.9)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata->transformers>=4.19.0->whisper==1.0) (3.8.1)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests->transformers>=4.19.0->whisper==1.0) (3.0.4)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests->transformers>=4.19.0->whisper==1.0) (1.24.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests->transformers>=4.19.0->whisper==1.0) (2022.6.15)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->transformers>=4.19.0->whisper==1.0) (2.10)\n",
            "Building wheels for collected packages: whisper\n",
            "  Building wheel for whisper (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for whisper: filename=whisper-1.0-py3-none-any.whl size=1175011 sha256=d8f3439af9cae3588b629b955b9c1b9ba1f0c4dd89c82bcae3a7ae81c52fd002\n",
            "  Stored in directory: /tmp/pip-ephem-wheel-cache-c_se2zcv/wheels/16/15/89/1c7bb31bd0006793a95549d04785121a8a36daad9158e1e43a\n",
            "Successfully built whisper\n",
            "Installing collected packages: tokenizers, huggingface-hub, transformers, ffmpeg-python, whisper\n",
            "Successfully installed ffmpeg-python-0.2.0 huggingface-hub-0.10.0 tokenizers-0.12.1 transformers-4.22.2 whisper-1.0\n"
          ]
        }
      ],
      "source": [
        "# google colab GPU version is extremely fast\n",
        "\n",
        "# https://github.com/openai/whisper\n",
        "# https://www.assemblyai.com/blog/how-to-run-openais-whisper-speech-recognition-model/\n",
        "\n",
        "!pip install git+https://github.com/openai/whisper.git\n",
        "\n",
        "import whisper\n",
        "import os\n",
        "\n",
        "\n",
        "def transcribe_audio(filename):\n",
        "    # can be tiny, base, small, medium and large\n",
        "    # colab crashes on large due to memory so use medium\n",
        "    model = whisper.load_model(\"medium\")\n",
        "\n",
        "    # load audio \n",
        "    # \"/content/\" is the directory used in Colab for file downloads (will be different for locally run notebook)\n",
        "    filename = \"/content/\" + filename\n",
        "    print(filename, \"start.\")\n",
        "    result = model.transcribe(filename)\n",
        "\n",
        "    # print transcription\n",
        "    output=result[\"text\"]\n",
        "    print(output)\n",
        "\n",
        "    # save file as markdown file\n",
        "    filename = filename[:-4]\n",
        "    with open(filename+\".md\", 'w') as f:    # save in markdown instead of .txt format\n",
        "        f.write(output)\n",
        "\n",
        "    return"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# read all files in specified directory\n",
        "file_list = os.listdir(path=r\"/content\")\n",
        "print(file_list)\n",
        "# transcribe each audio file in the directory\n",
        "# define acceptable filetypes to filter out colab .config and other non-audio files\n",
        "# the filetypes listed are the ones I am using but there could be others\n",
        "filetype = [\"m4a\", \"M4A\", \"wav\", \"WAV\", \"mp3\", \"MP3\"]\n",
        "\n",
        "index = 0\n",
        "while index < len(file_list):\n",
        "    filename = file_list[index]\n",
        "    print(filename[-3:])\n",
        "    if filename[-3:] in filetype:\n",
        "      print(filename, \"being transcribed...\")\n",
        "      transcribe_audio(filename)\n",
        "    index += 1\n",
        "    \n",
        "print(\"all files transcribed.\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "F8ijo5TjzVcE",
        "outputId": "d3af5627-affb-49d4-f1e7-6ec410329186"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['.config', 'sample_data']\n",
            "fig\n",
            "ata\n",
            "all files transcribed.\n"
          ]
        }
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3.8.13 ('pytorch-directml')",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.13"
    },
    "orig_nbformat": 4,
    "vscode": {
      "interpreter": {
        "hash": "79849614a1f070daf352e0af667e60a43e9406d771f853c326ca0f3fcc214227"
      }
    },
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 0
}