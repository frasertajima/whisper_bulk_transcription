{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ease deployment of CPU whisper by filling all settings. Setup is outlined in https://github.com/ggerganov/whisper.cpp. I had difficulty with CUDA in Fedora Silverblue (could only make in a distrobox and the end result had artefacts or hallucinations). This ASR has the highest accuracy and lowest speed.\n",
    "\n",
    "CAUTION: MAKE SURE TO BACKUP AUDIO FILES IF THEY HAVE SPACES IN THEIR NAMES AS THEY WILL BE RENAMED (AND THE METADATA ALTERED). For file names without spaces, the original file is not renamed and a copy is made in a compatible audio format."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5969.m2a\n",
      "5969.m2a-output.wav\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import subprocess\n",
    "import os\n",
    "import glob\n",
    "\n",
    "np.set_printoptions(linewidth=50)\n",
    "\n",
    "# change to reflect your local directory and file name\n",
    "home_directory = os.path.expanduser(\"~\")\n",
    "directory = home_directory + '/machine_learning/whisper.cpp/samples/'\n",
    "# ensure the spaces are replaced with '-' (cell below will rename files for ffmpeg processing)\n",
    "audio_file = '5969.m2a'\n",
    "output_file = audio_file + '-output.wav'\n",
    "print(audio_file)\n",
    "print(output_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# rename all audio files with spaces in their name\n",
    "# added *.m2a for podcasts\n",
    "files = glob.glob(os.path.join(directory, '*.m4a')) + \\\n",
    "        glob.glob(os.path.join(directory, '*.mp3')) + \\\n",
    "        glob.glob(os.path.join(directory, '*.m2a')) + \\\n",
    "        glob.glob(os.path.join(directory, '*.ogg')) + \\\n",
    "        glob.glob(os.path.join(directory, '*.wav'))\n",
    "\n",
    "# Iterate over the files \n",
    "for file in files:\n",
    "    # If the file name contains a space\n",
    "    if ' ' in file:\n",
    "        # Replace the spaces with hyphens\n",
    "        new_name = file.replace(' ', '-')\n",
    "        # Rename the file\n",
    "        os.rename(file, new_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Audio coverted successfully.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ffmpeg version 4.4 Copyright (c) 2000-2021 the FFmpeg developers\n",
      "  built with gcc 9.3.0 (crosstool-NG 1.24.0.133_b0863d8_dirty)\n",
      "  configuration: --prefix=/root/miniconda3/envs/conda_bld/conda-bld/ffmpeg_1635335682798/_h_env_placehold_placehold_placehold_placehold_placehold_placehold_placehold_placehold_placehold_placehold_placehold_placehold_placehold_placehold_placehold_placehold_placehold_placehold_place --cc=/root/miniconda3/envs/conda_bld/conda-bld/ffmpeg_1635335682798/_build_env/bin/x86_64-conda-linux-gnu-cc --disable-doc --disable-openssl --enable-avresample --enable-hardcoded-tables --enable-libfreetype --enable-libopenh264 --enable-pic --enable-pthreads --enable-shared --disable-static --enable-version3 --enable-zlib --enable-libmp3lame\n",
      "  libavutil      56. 70.100 / 56. 70.100\n",
      "  libavcodec     58.134.100 / 58.134.100\n",
      "  libavformat    58. 76.100 / 58. 76.100\n",
      "  libavdevice    58. 13.100 / 58. 13.100\n",
      "  libavfilter     7.110.100 /  7.110.100\n",
      "  libavresample   4.  0.  0 /  4.  0.  0\n",
      "  libswscale      5.  9.100 /  5.  9.100\n",
      "  libswresample   3.  9.100 /  3.  9.100\n",
      "Unknown attached picture mimetype: image/, skipping.\n",
      "[mp3 @ 0x55d8bcb41580] Estimating duration from bitrate, this may be inaccurate\n",
      "Input #0, mp3, from '/var/home/fraser/machine_learning/whisper.cpp/samples/5969.m2a':\n",
      "  Metadata:\n",
      "    title           : TNB Tech Minute: Netflix Considers Changing Its Corporate-Culture Memo\n",
      "    lyrics-ENG      : <p>Plus: Apple pays nearly $500 million to settle a lawsuit with investors. And India cuts import tariffs in an effort to woo Tesla. Alex Ossola hosts. </p>\n",
      "                    : <p><br></p>\n",
      "                    : <p>Listening on Google Podcasts? Here's our guide for switching to a different podcast player.</p>\n",
      "                    : <p><a href=\"http://WSJ.com/tech/Google-Podcasts\">WSJ.com/tech/Google-Podcasts</a> </p>\n",
      "                    : \n",
      "    artist          : The Wall Street Journal\n",
      "    album           : WSJ Tech News Briefing\n",
      "    genre           : Podcast\n",
      "    date            : 2019\n",
      "  Duration: 00:01:44.36, start: 0.000000, bitrate: 135 kb/s\n",
      "  Stream #0:0: Audio: mp3, 44100 Hz, stereo, fltp, 128 kb/s\n",
      "File '/var/home/fraser/machine_learning/whisper.cpp/samples/5969.m2a-output.wav' already exists. Overwrite? [y/N] Stream mapping:\n",
      "  Stream #0:0 -> #0:0 (mp3 (mp3float) -> pcm_s16le (native))\n",
      "Press [q] to stop, [?] for help\n",
      "Output #0, wav, to '/var/home/fraser/machine_learning/whisper.cpp/samples/5969.m2a-output.wav':\n",
      "  Metadata:\n",
      "    INAM            : TNB Tech Minute: Netflix Considers Changing Its Corporate-Culture Memo\n",
      "    lyrics-ENG      : <p>Plus: Apple pays nearly $500 million to settle a lawsuit with investors. And India cuts import tariffs in an effort to woo Tesla. Alex Ossola hosts. </p>\n",
      "                    : <p><br></p>\n",
      "                    : <p>Listening on Google Podcasts? Here's our guide for switching to a different podcast player.</p>\n",
      "                    : <p><a href=\"http://WSJ.com/tech/Google-Podcasts\">WSJ.com/tech/Google-Podcasts</a> </p>\n",
      "                    : \n",
      "    IART            : The Wall Street Journal\n",
      "    IPRD            : WSJ Tech News Briefing\n",
      "    IGNR            : Podcast\n",
      "    ICRD            : 2019\n",
      "    ISFT            : Lavf58.76.100\n",
      "  Stream #0:0: Audio: pcm_s16le ([1][0][0][0] / 0x0001), 16000 Hz, mono, s16, 256 kb/s\n",
      "    Metadata:\n",
      "      encoder         : Lavc58.134.100 pcm_s16le\n",
      "size=    3261kB time=00:01:44.35 bitrate= 256.0kbits/s speed= 896x    \n",
      "video:0kB audio:3261kB subtitle:0kB other streams:0kB global headers:0kB muxing overhead: 0.007546%\n"
     ]
    }
   ],
   "source": [
    "# convert audio_file then transcribe to text\n",
    "# overwrites existing file with same name\n",
    "try:\n",
    "    yes_command = f'echo \"y\" | '\n",
    "    subprocess.run([yes_command + 'ffmpeg' + ' -i ' + directory + audio_file + ' -ar 16000 -ac 1 -c:a pcm_s16le ' \n",
    "                    + directory + output_file], shell=True, check=True)\n",
    "    print(\"Audio coverted successfully.\")\n",
    "except subprocess.CalledProcessError as e:\n",
    "    print(f\"Audio convertion failed with error {e.returncode}.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\n# transcribe using the whisper-distill model: this model is halluciating presently\\n# but once that is fixed, I can swap out the slower CPU model for the CUDA enabled model\\n# so this code is for future use\\ntry:\\n    subprocess.run([\\'transcribe -t 24 -m /var/home/fraser/machine_learning/whisper.cpp/models/ggml-large-32-2.en.bin -f \\' \\n                    + directory + output_file + \\' -otxt\\'], shell=True, check=True)\\n    print(\"Transcription executed successfully and saved in \" + directory + output_file)\\nexcept subprocess.CalledProcessError as e:\\n    print(f\"Transcription failed with error {e.returncode}.\")\\n'"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''\n",
    "# transcribe using the whisper-distill model: this model is halluciating presently\n",
    "# but once that is fixed, I can swap out the slower CPU model for the CUDA enabled model\n",
    "# so this code is for future use\n",
    "try:\n",
    "    subprocess.run(['transcribe -t 24 -m /var/home/fraser/machine_learning/whisper.cpp/models/ggml-large-32-2.en.bin -f ' \n",
    "                    + directory + output_file + ' -otxt'], shell=True, check=True)\n",
    "    print(\"Transcription executed successfully and saved in \" + directory + output_file)\n",
    "except subprocess.CalledProcessError as e:\n",
    "    print(f\"Transcription failed with error {e.returncode}.\")\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "whisper_init_from_file_with_params_no_state: loading model from '/var/home/fraser/machine_learning/whisper.cpp/models/ggml-model-whisper-large-q5_0.bin'\n",
      "whisper_model_load: loading model\n",
      "whisper_model_load: n_vocab       = 51865\n",
      "whisper_model_load: n_audio_ctx   = 1500\n",
      "whisper_model_load: n_audio_state = 1280\n",
      "whisper_model_load: n_audio_head  = 20\n",
      "whisper_model_load: n_audio_layer = 32\n",
      "whisper_model_load: n_text_ctx    = 448\n",
      "whisper_model_load: n_text_state  = 1280\n",
      "whisper_model_load: n_text_head   = 20\n",
      "whisper_model_load: n_text_layer  = 32\n",
      "whisper_model_load: n_mels        = 80\n",
      "whisper_model_load: ftype         = 8\n",
      "whisper_model_load: qntvr         = 1\n",
      "whisper_model_load: type          = 5 (large)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "whisper_model_load: adding 1608 extra tokens\n",
      "whisper_model_load: n_langs       = 99\n",
      "whisper_model_load:      CPU total size =  1080.10 MB\n",
      "whisper_model_load: model size    = 1080.10 MB\n",
      "whisper_init_state: kv self size  =  220.20 MB\n",
      "whisper_init_state: kv cross size =  245.76 MB\n",
      "whisper_init_state: compute buffer (conv)   =   34.82 MB\n",
      "whisper_init_state: compute buffer (encode) =  926.66 MB\n",
      "whisper_init_state: compute buffer (cross)  =    9.38 MB\n",
      "whisper_init_state: compute buffer (decode) =  209.26 MB\n",
      "\n",
      "system_info: n_threads = 24 / 24 | AVX = 1 | AVX2 = 1 | AVX512 = 0 | FMA = 1 | NEON = 0 | ARM_FMA = 0 | METAL = 0 | F16C = 1 | FP16_VA = 0 | WASM_SIMD = 0 | BLAS = 0 | SSE3 = 1 | SSSE3 = 1 | VSX = 0 | CUDA = 0 | COREML = 0 | OPENVINO = 0\n",
      "\n",
      "main: processing '/var/home/fraser/machine_learning/whisper.cpp/samples/5969.m2a-output.wav' (1669747 samples, 104.4 sec), 24 threads, 1 processors, 5 beams + best of 5, lang = en, task = transcribe, timestamps = 1 ...\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[00:00:00.000 --> 00:00:05.520]   Here's your TNB Tech Minute for Friday, March 15.\n",
      "[00:00:05.520 --> 00:00:08.880]   I'm Alex Ossola for The Wall Street Journal.\n",
      "[00:00:08.880 --> 00:00:11.320]   Changes may be coming for Netflix's culture.\n",
      "[00:00:11.320 --> 00:00:15.480]   We are exclusively reporting that the streaming giant is discussing removing the freedom and\n",
      "[00:00:15.480 --> 00:00:19.980]   responsibility section from the corporate culture memo that the company often cites\n",
      "[00:00:19.980 --> 00:00:22.320]   as a blueprint for its success.\n",
      "[00:00:22.320 --> 00:00:24.940]   That's according to people familiar with the situation.\n",
      "[00:00:24.940 --> 00:00:29.300]   The change would be part of a larger revamp of the culture memo meant to shorten and simplify\n",
      "[00:00:29.300 --> 00:00:31.820]   it for employees and recruits.\n",
      "[00:00:31.820 --> 00:00:36.520]   Other substantial changes would include emphasizing creativity and creative freedom.\n",
      "[00:00:36.520 --> 00:00:39.560]   A Netflix spokeswoman declined to comment.\n",
      "[00:00:39.560 --> 00:00:45.680]   Apple has reached a $490 million settlement in a class-action lawsuit brought by investors.\n",
      "[00:00:45.680 --> 00:00:49.640]   The plaintiffs said the company concealed falling demand for the iPhone in China in\n",
      "[00:00:49.640 --> 00:00:50.800]   2018.\n",
      "[00:00:50.800 --> 00:00:55.640]   Apple denied any wrongdoing in the settlement agreement and said it settled to avoid a protracted\n",
      "[00:00:55.640 --> 00:00:57.560]   and costly legal fight.\n",
      "[00:00:57.560 --> 00:00:59.720]   Apple declined to comment further.\n",
      "[00:00:59.720 --> 00:01:05.080]   A lawyer for the plaintiffs said the settlement was a terrific outcome for shareholders.\n",
      "[00:01:05.080 --> 00:01:10.200]   And India says that it will cut import duties for manufacturers who invest at least $500\n",
      "[00:01:10.200 --> 00:01:13.280]   million to produce their cars in the country.\n",
      "[00:01:13.280 --> 00:01:16.200]   It's a move largely aimed at wooing Tesla.\n",
      "[00:01:16.200 --> 00:01:21.360]   Since a June meeting between Tesla CEO Elon Musk and Indian Prime Minister Narendra Modi,\n",
      "[00:01:21.360 --> 00:01:25.640]   Tesla executives and top Indian officials have been in months of talks.\n",
      "[00:01:25.640 --> 00:01:30.180]   Tesla is seeking to first import its premium cars to India to establish a market while\n",
      "[00:01:30.180 --> 00:01:34.880]   setting up a factory to produce a more affordable variant, according to a senior Indian government\n",
      "[00:01:34.880 --> 00:01:35.880]   official.\n",
      "[00:01:35.880 --> 00:01:39.720]   Tesla didn't immediately respond to a request for comment.\n",
      "[00:01:39.720 --> 00:01:43.440]   For a deeper dive into what's happening in tech, check out Monday's Tech News Briefing\n",
      "\n",
      "Transcription executed successfully and saved in /var/home/fraser/machine_learning/whisper.cpp/samples/5969.m2a-output.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "output_txt: saving output to '/var/home/fraser/machine_learning/whisper.cpp/samples/5969.m2a-output.wav.txt'\n",
      "\n",
      "whisper_print_timings:     load time =   612.55 ms\n",
      "whisper_print_timings:     fallbacks =   0 p /   0 h\n",
      "whisper_print_timings:      mel time =    84.26 ms\n",
      "whisper_print_timings:   sample time =  1481.43 ms /  2035 runs (    0.73 ms per run)\n",
      "whisper_print_timings:   encode time = 171134.75 ms /     4 runs (42783.69 ms per run)\n",
      "whisper_print_timings:   decode time =   178.11 ms /     1 runs (  178.11 ms per run)\n",
      "whisper_print_timings:   batchd time = 201103.80 ms /  2017 runs (   99.70 ms per run)\n",
      "whisper_print_timings:   prompt time = 24799.77 ms /   571 runs (   43.43 ms per run)\n",
      "whisper_print_timings:    total time = 399412.91 ms\n"
     ]
    }
   ],
   "source": [
    "# transcribe using the large quantized CPU model, output text file\n",
    "try:\n",
    "    subprocess.run(['transcribe -t 24 -m ' + home_directory + '/machine_learning/whisper.cpp/models/ggml-model-whisper-large-q5_0.bin -f ' \n",
    "                    + directory + output_file + ' -otxt'], shell=True, check=True)\n",
    "    print(\"Transcription executed successfully and saved in \" + directory + output_file)\n",
    "except subprocess.CalledProcessError as e:\n",
    "    print(f\"Transcription failed with error {e.returncode}.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "7m to transcribe a 2:24m file, but all punctuation, etc., is *perfect*. whisper-distil on CUDA takes 2.6s but has some errors. Attempts at injecting markdown formatting commands failed as the command is surrounded by ' ' for some odd reason. When this changes, it should be possible to inject formatting while dictating."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "py310",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
